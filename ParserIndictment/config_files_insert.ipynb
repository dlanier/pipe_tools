{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config file open compare: full code condensate\n",
    "[Current](https://git.ncsa.illinois.edu/mayomics/MayomicsVC/blob/master/src/python/config/parser/parsing.py) <br>\n",
    "* dakine\n",
    "\n",
    "```python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def read_input_file(self, file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as F:\n",
    "            return F.read().splitlines()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        self.project_logger.log_error(\"E.par.Fil.1\", 'Input file \"' + str(file_path) + '\" could not be found')\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def remove_comments(input_lines):\n",
    "    \"\"\"\n",
    "     Remove any comment lines from the list of lines\n",
    "\n",
    "       A comment line is a line where the first non-whitespace character is a '#'\n",
    "    \"\"\"\n",
    "    filtered_lines = []\n",
    "    for line in input_lines:\n",
    "        if line != \"\":\n",
    "            # If the first non-space character is a '#', exclude it\n",
    "            if len(line.strip()) > 0 and line.strip()[0] != '#':\n",
    "                filtered_lines.append(line)\n",
    "    return filtered_lines\n",
    "\n",
    "\n",
    "def clean_input_file(input_lines):\n",
    "        \"\"\"\n",
    "         Takes in a list of input lines, and removes any blank and comment lines (lines beginning with '#')\n",
    "        \"\"\"\n",
    "        # Remove all blank lines\n",
    "        non_empty_lines = list(filter(None, input_lines))\n",
    "        return Parser.remove_comments(non_empty_lines)\n",
    "    \n",
    "    \n",
    "def create_key_value_pairs(self, input_lines, file_path):\n",
    "        \"\"\"\n",
    "        Turns a list of lines with keys and values separated by a '=' into pairs of (key, value) tuples\n",
    "        \"\"\"\n",
    "        key_value_pairs = []\n",
    "\n",
    "        for line in input_lines:\n",
    "            if \"=\" not in line:\n",
    "                self.project_logger.log_error(\n",
    "                    \"E.par.NEq.1\",\n",
    "                    \"No equals sign present in line '\" + line + \"' from input file '\" + file_path + \"'\"\n",
    "                )\n",
    "                sys.exit(1)\n",
    "            else:\n",
    "                # Get the position of the first equals sign (assumes there is no '=' in the key name)\n",
    "                split_pos = line.index(\"=\")\n",
    "                key = line[0:split_pos]\n",
    "                value = line[split_pos + 1:]\n",
    "                key_value_pairs.append((key, value))\n",
    "        return key_value_pairs\n",
    "    \n",
    "def validate_key_value_pairs(self, key_value_pairs, file_path):\n",
    "    \"\"\"\n",
    "     Takes in a list of (Key, Value) tuples, and confirms that they are valid (or throws an error)\n",
    "\n",
    "    Keys that are allowed to be empty are not checked (see src/config/util/special_keys.py)\n",
    "\n",
    "     Checks performed:\n",
    "        1. Verifies that all Keys have an associated Value\n",
    "        2. Verifies that the Value is enclosed in double quotes\n",
    "        3. Verifies that no special characters are present in the Values\n",
    "        4. Verifies that no Key is present more than once\n",
    "        5. Verifies that no value is whitespace only\n",
    "    \"\"\"\n",
    "    # List comprehensions to create complete list of keys\n",
    "    keys_list = [k for k, v in key_value_pairs]\n",
    "\n",
    "    for key, value in key_value_pairs:\n",
    "        if key.lower() in OPTIONAL_KEYS and (value == \"\" or value == '\"\"'):\n",
    "            # These keys are allowed to have empty values, \n",
    "            # do not perform checking (simply write a debug message)\n",
    "            self.project_logger.log_debug(\n",
    "                \"The key '\" + key + \"' had an empty value; since its value is optional, no error was thrown\"\n",
    "            )\n",
    "        else:\n",
    "            # Check that the value is not empty\n",
    "            if value == '':\n",
    "                self.project_logger.log_error(\n",
    "                    \"E.par.NVa.1\",\n",
    "                    \"No value present for key '\" + key + \"' in input file '\" + file_path + \"'\"\n",
    "                )\n",
    "            # Check that the value is enclosed in double quotes\n",
    "            elif value[0] != '\"' or value[-1] != '\"':\n",
    "                self.project_logger.log_error(\n",
    "                    \"E.par.NQt.1\",\n",
    "                    \"No quotes around the value for key '\" + key + \"' in input file '\" + file_path + \"'\"\n",
    "                )\n",
    "            # Check to see that non-whitespace are present between the quote marks\n",
    "            # value[1:-1] trims off the first and last chars and \n",
    "            # strip removes all whitespace chars from the ends\n",
    "            elif value[1:-1].strip() == '':\n",
    "                self.project_logger.log_error(\n",
    "                    \"E.par.WhS.1\",\n",
    "                    \"Only whitespace found in value '\" + value + \"' of key '\" + key + \"' in input file '\" +\n",
    "                    file_path + \"'\"\n",
    "                )\n",
    "            # Check if any special characters are present\n",
    "            special_chars = \"!#DOLLARSIGNREMOVED%&()*;<>?@[]^`{|}~\"\n",
    "            for special_char in special_chars:\n",
    "                if special_char in value:\n",
    "                    self.project_logger.log_error(\n",
    "                        \"E.par.SpC.1\",\n",
    "                        \"Invalid special character '\" + special_char + \"' found in value '\" + value +\n",
    "                        \"' of key '\" + key + \"' in input file '\" + file_path + \"'\"\n",
    "                    )\n",
    "            # Check whether any key is present multiple times\n",
    "            if keys_list.count(key) > 1:\n",
    "                self.project_logger.log_error(\n",
    "                    \"E.par.Key.1\", \"Key '\" + key + \n",
    "                    \"' is present more than once in input file '\" + file_path + \"'\"\n",
    "                )\n",
    "            else:\n",
    "                self.project_logger.log_debug(\"The key-value pair '\" + key + \"=\" + value + \"' is a valid pair\")\n",
    "\n",
    "\n",
    "\n",
    "def combine_input_read_arrays(self, key_value_tuples, read1_name, read2_name):\n",
    "    \"\"\"\n",
    "    Takes in the key value tuples, and the names of two read variables, \n",
    "    and combines their values into a 2D array\n",
    "    (This is used for two pairs of reads: NormalInputReads and TumorInputReads)\n",
    "\n",
    "    InputReads1 & 2 are each provided in the config file as an array of files\n",
    "\n",
    "        InputRead1=\"L1,L2,L3, ...\"\n",
    "        InputRead2=\"R1,R2,R3, ...\"\n",
    "\n",
    "    These two lists will be combined into a single 2D-array variable called InputReads.\n",
    "\n",
    "    How they are combined depends on the value of the PairedEnd flag\n",
    "\n",
    "    If PairedEnd and data in both input variables\n",
    "        InputRead = [ [L1, R1], [L2, R2], [L3, R3] ]\n",
    "\n",
    "    If not PairedEnd and data in both input variables\n",
    "        InputRead = [ [L1], [L2], [L3], [R1], [R2], [R3] ]\n",
    "\n",
    "    If not PairedEnd and data only in InputRead1\n",
    "        InputRead = [ [L1], [L2], [L3] ]\n",
    "\n",
    "    Throw an error if:\n",
    "        1. PairedEnd, InputRead1, or InputRead2 are not defined in the input tuple list\n",
    "        1. PairedEnd is true and data only InputRead1 is set\n",
    "        2. PairedEnd is true and the number of entries between the input variables are different\n",
    "\n",
    "    :return: The 2-D array holding the values that will be the value of the InputReads key in the JSON file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # next iterates through a collection until it finds an item that meets a criterion; here it is used to\n",
    "        #   find the tuples with the keys we want\n",
    "        paired_end_tuple = next(pair for pair in key_value_tuples if pair[0] == \"PairedEnd\")\n",
    "        input_read_1_tuple = next(pair for pair in key_value_tuples if pair[0] == read1_name)\n",
    "        input_read_2_tuple = next(pair for pair in key_value_tuples if pair[0] == read2_name)\n",
    "\n",
    "        paired_end = True if paired_end_tuple[1].strip('\"') == \"true\" else False\n",
    "\n",
    "        # Split by comma (unless the string is empty, then return an empty list)\n",
    "        input_read_1_value = input_read_1_tuple[1].strip('\"')\n",
    "        input_read_2_value = input_read_2_tuple[1].strip('\"')\n",
    "\n",
    "        input_read_1_array = [] if input_read_1_value == \"\" else input_read_1_value.split(\",\")\n",
    "        input_read_2_array = [] if input_read_2_value == \"\" else input_read_2_value.split(\",\")\n",
    "\n",
    "        if paired_end:\n",
    "            if len(input_read_2_array) == 0:\n",
    "                self.project_logger.log_error(\"E.par.InR.3\",\n",
    "                                              \"PairedEnd was true but the \" + read2_name + \" lists were empty\"\n",
    "                                              )\n",
    "                sys.exit(1)\n",
    "            elif len(input_read_1_array) != len(input_read_2_array):\n",
    "                self.project_logger.log_error(\n",
    "                    \"E.par.InR.2\",\n",
    "                    \"The \" + read1_name + \" & \" + read2_name + \" lists had different lengths\"\n",
    "                )\n",
    "                sys.exit(1)\n",
    "\n",
    "            # By default, zip returns tuples. The list comprehension turns them back into lists\n",
    "            input_reads_2d_array = [list(x) for x in list(zip(input_read_1_array, input_read_2_array))]\n",
    "        else:\n",
    "            # Concatenate the two lists, then turn each entry into its own list\n",
    "            input_reads_2d_array = [[x] for x in input_read_1_array + input_read_2_array]\n",
    "\n",
    "        return input_reads_2d_array\n",
    "\n",
    "    except StopIteration:\n",
    "        self.project_logger.log_error(\n",
    "            \"E.par.InR.1\",\n",
    "            \"Either the PairedEnd, \" + read1_name + \", or \" + read2_name + \n",
    "            \" key was not present in the config file\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "def insert_values_into_dict(self,\n",
    "                            starting_dict,\n",
    "                            key_value_tuple,\n",
    "                            normal_input_reads_2d_array,\n",
    "                            tumor_input_reads_2d_array=None\n",
    "                            ):\n",
    "    \"\"\"\n",
    "     Takes an initial dictionary and a list of (Key, Value) tuples.\n",
    "       The Values in the tuple list are placed in the initial dictionary by Key.\n",
    "\n",
    "    :param starting_dict = The dictionary derived from the original JSON template\n",
    "    :param key_value_tuple = The complete list of keys and values (as tuples) that were in the config files\n",
    "    :param normal_input_reads_2d_array = The 2D array that will be the value of the JSON \"NormalInputReads\" key\n",
    "    :param tumor_input_reads_2d_array = 2D array that will be the value of the \"TumorInputReads\" key \n",
    "        (if it is used)\n",
    "\n",
    "    :return The dictionary with all of the values inserted\n",
    "    \"\"\"\n",
    "    output_dict = starting_dict.copy()\n",
    "\n",
    "    # Switches so internal if statements are not run repeatedly\n",
    "    normal_input_reads_found = False\n",
    "    tumor_input_reads_found = False\n",
    "\n",
    "\n",
    "    # For each key-value pair that will be substituted into the dictionary\n",
    "    for config_key, config_value in key_value_tuple:\n",
    "        # Switch signaling whether the key from the config file was found in the json template\n",
    "        config_key_was_present = False\n",
    "\n",
    "        # Loop through each key, and pattern match to see if the config_key is found in this starting_dict.key\n",
    "        for dict_key in starting_dict.keys():\n",
    "            #  config_key matches the last section of this starting_dict.key\n",
    "            #    keys are structured Major.Minor.KeyName, and we are matching against the KeyName\n",
    "            dict_key_suffix = dict_key.split(\".\")[-1]\n",
    "\n",
    "            if config_key == dict_key_suffix:\n",
    "                config_key_was_present = True\n",
    "\n",
    "                # Remove quote marks from the ends of the original value; assumes that the value was wrapped in\n",
    "                #   quote marks (if it got past the validate_key_value_pairs method, this is guaranteed)\n",
    "                trimmed_value = config_value[1:-1]\n",
    "\n",
    "                # Special case where the value should be split into an array\n",
    "                if dict_key_suffix == \"PlatformUnit\":\n",
    "                    output_dict[dict_key] = trimmed_value.split(\",\")\n",
    "                else:\n",
    "                    output_dict[dict_key] = trimmed_value\n",
    "\n",
    "                # Handle special keys that need additional json keys added for each config key \n",
    "                # (such as REF, DBSNP)\n",
    "                self.handle_special_keys(config_key, dict_key, output_dict, trimmed_value)\n",
    "\n",
    "            # Add the special key, NormalInputReads, to the dictionary\n",
    "            elif dict_key_suffix == \"NormalInputReads\" and not normal_input_reads_found:\n",
    "                output_dict[dict_key] = normal_input_reads_2d_array\n",
    "                # Flip the switch so that this conditional is not evaluated again\n",
    "                normal_input_reads_found = True\n",
    "\n",
    "            elif dict_key_suffix == \"TumorInputReads\" and \\\n",
    "                    tumor_input_reads_2d_array is not None and \\\n",
    "                    not tumor_input_reads_found:\n",
    "                self.project_logger.log_debug(\n",
    "                    \"The TumorInputReads JSON key was paired with a 2D array created from the \" +\n",
    "                    \"TumorInputRead1 and 2 variables\"\n",
    "                )\n",
    "                output_dict[dict_key] = tumor_input_reads_2d_array\n",
    "                # Flip the switch so that this conditional is not evaluated again\n",
    "                tumor_input_reads_found = True\n",
    "\n",
    "\n",
    "        # Log a warning message if a key was in the config file but not in the template\n",
    "        exception_list = [\"NormalInputRead1\", \"NormalInputRead2\", \"TumorInputRead1\", \"TumorInputRead2\"]\n",
    "        if not config_key_was_present and config_key not in exception_list:\n",
    "            self.project_logger.log_warning(\n",
    "                \"Key '\" + config_key + \"' had no corresponding key in the JSON template;\" +\n",
    "                \" this key-value pair was ignored\"\n",
    "            )\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def find_variables_in_JSON_not_in_config(self, all_config_tuples, JSON_dict):\n",
    "    \"\"\"\n",
    "    Warns the user if any JSON key was not present in the configuration tuple list (that are not in the exception\n",
    "      list).\n",
    "\n",
    "    Since there are some keys that are added to the JSON that are not part of the config file directly (see the\n",
    "      \"handle_special_keys\" method), they are not sought for in the config keys list, \n",
    "          and are put in the exception list\n",
    "\n",
    "    :param all_config_tuples: list of all config file tuples\n",
    "    :param JSON_dict: Python dictionary from the template JSON file\n",
    "    \"\"\"\n",
    "    exception_list = (\"RefAmb\", \"RefAnn\", \"RefBwt\", \"RefDict\", \"RefPac\", \"RefSa\",\n",
    "                      \"DBSNPIdx\",\n",
    "                      \"NormalInputReads\", \"TumorInputReads\"\n",
    "                      )\n",
    "\n",
    "    # The informative part of the JSON key is the subsection after the last '.' character\n",
    "    trimmed_JSON_keys = list(set([i.split(\".\")[-1] for i in JSON_dict.keys()]))\n",
    "    config_keys = [i[0] for i in all_config_tuples]\n",
    "\n",
    "    for json_key in trimmed_JSON_keys:\n",
    "        if json_key not in exception_list and json_key not in config_keys:\n",
    "            self.project_logger.log_error(\n",
    "                \"E.par.NoJ.1\",\n",
    "                \"The '\" + json_key + \n",
    "                \"' key in the JSON template did not have a corresponding key in any of the \" +\n",
    "                \"config files; this key was not filled in\")\n",
    "\n",
    "```\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def fill_in_json_template(self, input_file_list, json_template_file, output_file):\n",
    "    \"\"\"\n",
    "     Takes in a list of input files and the location of the json file template, and writes an output file\n",
    "       that contains the template's keys filled in with values from the input files\n",
    "\n",
    "     The original template files contents will be copied, filled-in, and saved in the new output file\n",
    "    \"\"\"\n",
    "    # Read in the information from the json template file as a Python Dictionary\n",
    "    #   The values of the template dictionary are filled in as input files are processed\n",
    "    template_dict = read_json_file(json_template_file, self.project_logger,\n",
    "                                   json_not_found_error_code=\"E.par.JSN.1\",\n",
    "                                   json_bad_format_error_code=\"E.par.JSN.2\")\n",
    "\n",
    "    # Combine all of the input file key-value tuples into a single list\n",
    "    all_key_value_tuples = []\n",
    "\n",
    "    # This loop iterates through all the input files and parses the path information\n",
    "    for input_file in input_file_list:\n",
    "        # Read in and clean the input file\n",
    "        raw_input_lines = self.read_input_file(input_file)\n",
    "        input_lines = self.clean_input_file(raw_input_lines)\n",
    "\n",
    "        # Turn input lines into Tuples of Key-Value pairs\n",
    "        key_value_tuples = self.create_key_value_pairs(input_lines, file_path=input_file)\n",
    "        # Validate the key-value entries (Returns nothing; only possible outputs are error messages)\n",
    "        self.validate_key_value_pairs(key_value_tuples, file_path=input_file)\n",
    "\n",
    "        # Add all of the pairs from this file into the overall list of pairs\n",
    "        [all_key_value_tuples.append(pair) for pair in key_value_tuples]\n",
    "\n",
    "    # Create the NormalInputReads value from the info in the config files (Always required)\n",
    "    normal_input_reads_2d_array = self.combine_input_read_arrays(all_key_value_tuples,\n",
    "                                                                 \"NormalInputRead1\",\n",
    "                                                                 \"NormalInputRead2\")\n",
    "\n",
    "    # Optionally, create the TumorInputReads value from the info in the config files (will be a 2D array if\n",
    "    #   TumorInputRead1 was not empty, and None otherwise)\n",
    "    if self.is_TumorInputRead1_present(all_key_value_tuples):\n",
    "        tumor_input_reads_2d_array = self.combine_input_read_arrays(all_key_value_tuples,\n",
    "                                                                    \"TumorInputRead1\",\n",
    "                                                                    \"TumorInputRead2\")\n",
    "        template_dict = self.insert_values_into_dict(template_dict,\n",
    "                                                     all_key_value_tuples,\n",
    "                                                     normal_input_reads_2d_array,\n",
    "                                                     tumor_input_reads_2d_array\n",
    "                                                     )\n",
    "    else:\n",
    "        # Update the values in the template dictionary\n",
    "        template_dict = self.insert_values_into_dict(template_dict,\n",
    "                                                     all_key_value_tuples,\n",
    "                                                     normal_input_reads_2d_array\n",
    "                                                     )\n",
    "\n",
    "    # Send a warning if any JSON keys had no corresponding key in any of the config files\n",
    "    self.find_variables_in_JSON_not_in_config(all_key_value_tuples, template_dict)\n",
    "\n",
    "    # Write the python dictionary out as a JSON file in the output file location\n",
    "    with open(output_file, \"w\") as updated_json:\n",
    "        json.dump(template_dict, updated_json, indent=4, sort_keys=True)\n",
    "\n",
    "    # Exit if errors have occurred\n",
    "    if self.project_logger.errors_issued > 0:\n",
    "        self.project_logger.log_info(\n",
    "            'Configuration file parser failed with ' + \n",
    "            str(self.project_logger.errors_issued) + \n",
    "            ' error(s) issued')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        # Write a success message to the log\n",
    "        self.project_logger.log_info(\n",
    "            'Configuration file parser finished successfully with ' + \n",
    "            str(self.project_logger.warnings_issued) + \n",
    "            ' warning(s) issued')\n",
    "\n",
    "```\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists =  True \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "def read_txt_file(fname):\n",
    "    with open(fname,'r') as fh:\n",
    "        return fh.read().splitlines()\n",
    "\n",
    "def fill_in_template_with_config(input_file_list, json_template_file, output_file):\n",
    "    with open(json_template_file, 'r') as fh:\n",
    "        json_dict = json.loads(fh.read())\n",
    "    \n",
    "    infile_tuples_list = []\n",
    "    for config_file in input_file_list:\n",
    "        lines = read_txt_file(fname=config_file)\n",
    "        for line in lines:\n",
    "            if len(line) > 0 and line[0] != \"#\" and \"=\" in line:\n",
    "                line_list = line.split(\"=\")\n",
    "                if len(line_list) == 2 and len(line_list[0]) > 0 and len(line_list[1]) > 0:\n",
    "                    infile_tuples_list.append((line_list[0], line_list[1]))\n",
    "                    \"\"\"       Ignore the special characters check for now       \"\"\"\n",
    "    if len(infile_tuples_list) > 0:\n",
    "        # combine_input_read_arrays\n",
    "        # insert_values_into_dict\n",
    "        # find_variables_in_JSON_not_in_config\n",
    "        # json dump dakine\n",
    "        \n",
    "    return 0\n",
    "    \n",
    "    \n",
    "\n",
    "jsonTemplate = '../data/GermlineParameters/Jsons/GermlineMasterWorkflow.template.json'\n",
    "json_filled_in = '../data/GermlineParameters/Jsons/GermlineMasterWorkflow.BAK.FilledIn.json'\n",
    "#                   Sets all cells on the page:\n",
    "json_compare_file = jsonTemplate\n",
    "print('File exists = ',os.path.isfile(json_compare_file),'\\n')\n",
    "\n",
    "ConfigsBeingUsed = ['../data/GermlineParameters/Config/memory_info.txt']\n",
    "ConfigsBeingUsed.append('../data/GermlineParameters/Config/tool_info.txt')\n",
    "ConfigsBeingUsed.append('../data/GermlineParameters/Config/sample_info.txt')\n",
    "ConfigsBeingUsed.append('../data/GermlineParameters/Config/run_info.txt')\n",
    "\n",
    "output_file = 'not4real.json'\n",
    "\n",
    "\n",
    "fill_in_template_with_config(input_file_list=ConfigsBeingUsed, \n",
    "                             json_template_file=json_compare_file, \n",
    "                             output_file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
