{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ConfigsBeingUsed = \"-i Config/run_info.txt -i Config/tool_info.txt -i Config/memory_info.txt -i Config/sample_info.txt\"\n",
    "python MayomicsVC/src/python/config_parser.py ConfigsBeingUsed --jsonTemplate Jsons/GermlineMasterWorkflow.template.json -o Jsons/GermlineMasterWorkflow.FilledIn.json;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "conf_dir = '../../data/Config'\n",
    "json_dir = '../../data/Jsons'\n",
    "mayo_repo = '../../../../ncsa_genomics/MayomicsVC'\n",
    "\n",
    "mayo_python_code = os.path.join(mayo_repo, 'src/python')\n",
    "sys.path.insert(1, mayo_python_code)\n",
    "import config_parser\n",
    "\n",
    "mayo_python_parser_code = os.path.join(mayo_python_code, 'config/parser')\n",
    "sys.path.insert(1, mayo_python_parser_code)\n",
    "from parsing import Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dir = '../../data/Config'\n",
    "json_dir = '../../data/Jsons'\n",
    "mayo_repo = '../../../../ncsa_genomics/MayomicsVC'\n",
    "mayo_python_code = os.path.join(mayo_repo, 'src/python')\n",
    "# os.listdir(conf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template = os.path.join(json_dir, 'GermlineMasterWorkflow.template.json')\n",
    "json_test_template = os.path.join(json_dir, 'GermlineMasterWorkflow.templateSAVEME.json')\n",
    "json_output = os.path.join(json_dir, 'GermlineMasterWorkflow.FilledInTest.json')\n",
    "config_files = ['run_info.txt', 'tool_info.txt', 'memory_info.txt', 'sample_info.txt']\n",
    "config_full_files = []\n",
    "for conf_file in config_files:\n",
    "    config_full_files.append(os.path.join(conf_dir, conf_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobID = '23Skidoo'\n",
    "debugmode = False\n",
    "k_v_parser = Parser(jobID, debugmode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'InputReads' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'Strelka' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'StrelkaThreads' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'Mutect' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'MutectThreads' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'DeliverySomaticVC_Script' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'StrelkaScript' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'MutectScript' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'MergeSomaticVcfScript' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'StrelkaEnvProfile' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'MutectEnvProfile' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [WARNING] [parser.parsing.Parser] [23Skidoo] [-] Key 'MergeSomaticVcfEnvProfile' had no corresponding key in the JSON template; this key-value pair was ignored\n",
      "[2019-01-11T10:59:37-0600] [INFO] [parser.parsing.Parser] [23Skidoo] [-] Configuration file parser finished successfully with 12 warning(s) issued\n"
     ]
    }
   ],
   "source": [
    "os.listdir(json_dir)\n",
    "# config_full_files == parsed_args.i\n",
    "# json_template == parsed_args.jsonTemplate\n",
    "# json_output == parsed_args.o\n",
    "k_v_parser.fill_in_json_template(config_full_files, json_template, json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_del_keys(config_file, key_names_list):\n",
    "    \"\"\" Usage: new_lines_list = template_del_keys(config_file, key_names_list) \"\"\"\n",
    "    \n",
    "    print('Opening:\\n', config_file)\n",
    "    with open(config_file, 'r') as tfh:\n",
    "        lines = tfh.readlines()\n",
    "    print('found %i lines'%(len(lines)))\n",
    "    new_lines_list = ['{\\n']\n",
    "    for line in lines:\n",
    "        l_key = line.strip().split('=')[0]\n",
    "        for key_name in key_names_list:\n",
    "            if not key_name in l_key:\n",
    "                new_lines_list.append('  ' + line.strip() + '\\n')\n",
    "            else:\n",
    "                print('removeing\\n', line.strip())\n",
    "                \n",
    "    new_lines_list.append('}')\n",
    "    outie_full_file, fext = os.path.splitext(config_file)\n",
    "    outie_full_file = outie_full_file + '.cleaned' + fext\n",
    "    print(outie_full_file)\n",
    "    \n",
    "    return new_lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening:\n",
      " ../../data/Config/sample_info.txt\n",
      "found 1 lines\n",
      "../../data/Config/sample_info.cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "nix_key_list = ['InputReads', \n",
    "                'Strelka', \n",
    "                'StrelkaThreads', \n",
    "                'Mutect', \n",
    "                'MutectThreads', \n",
    "                'DeliverySomaticVC_Script', \n",
    "                'StrelkaScript', \n",
    "                'MutectScript', \n",
    "                'MergeSomaticVcfScript', \n",
    "                'StrelkaEnvProfile', \n",
    "                'MutectEnvProfile', \n",
    "                'MergeSomaticVcfEnvProfile']\n",
    "new_lines_list = template_del_keys(config_file=config_full_files[3], key_names_list=nix_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GermlineMasterWF.merge.MergeSoftMemLimit'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = '  \"GermlineMasterWF.merge.MergeSoftMemLimit\": \"String\",'\n",
    "l_key = line.strip().strip('\"').split(':')[0].strip('\"')\n",
    "l_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_keys_list(json_full_file):\n",
    "    \"\"\" Usage: keys_list = get_json_keys_list(json_full_file) \"\"\"\n",
    "    keys_list = []\n",
    "    with open(json_full_file, 'r') as tfh:\n",
    "        lines = tfh.readlines()\n",
    "        \n",
    "    print('found %i lines'%(len(lines)))\n",
    "\n",
    "    for line in lines:\n",
    "        l_key = line.strip().strip('\"').split(':')[0]\n",
    "        l_key = l_key.strip('\"').split('.')[-1]\n",
    "        if not l_key is None and len(l_key) > 0:\n",
    "            keys_list.append(str(l_key))\n",
    "        \n",
    "    return keys_list\n",
    "\n",
    "def get_keys_dict(config_full_file):\n",
    "    \"\"\" Usage: config_dict = get_keys_dict(config_full_file) \"\"\"\n",
    "    config_dict = {}\n",
    "    with open(config_full_file, 'r') as cfh:\n",
    "        lines = cfh.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        l_list = line.strip().replace('\"\"', '').split('=')\n",
    "        \n",
    "        if len(l_list) >= 1:\n",
    "            l_key = l_list[0]\n",
    "            \n",
    "            if len(l_key) >=1 and l_key[0] != '#':\n",
    "                if len(l_list) <= 1 or l_list[1] is None:\n",
    "                    config_dict[l_key] = ''\n",
    "                elif len(l_list) == 2:\n",
    "                    config_dict[l_key] = ''.join(l_list[1:][0])\n",
    "                else:\n",
    "                    config_dict[l_key] = ' '.join(l_list[1:])\n",
    "                \n",
    "    return config_dict\n",
    "\n",
    "def config_list_to_json_dict(config_full_files_list, json_full_file):\n",
    "    \"\"\" Usage: jsonic_dict, missing_keys_list = config_list_to_json_dict(config_full_files_list, json_full_file) \n",
    "    \n",
    "    \"\"\"\n",
    "    missing_keys_list = []\n",
    "    jsonic_dict = {}\n",
    "    return jsonic_dict, missing_keys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_test_template = os.path.join(json_dir, 'GermlineMasterWorkflow.templateSAVEME.json')\n",
    "jsonic_dict, missing_keys_list = config_list_to_json_dict(config_full_files_list=config_full_files, \n",
    "                                                          json_full_file=json_test_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "<class 'str'> \tDebugMode: \n",
      "\t\n",
      "\n",
      "<class 'str'> \tPairedEnd: \n",
      "\t\"true\"\n",
      "\n",
      "<class 'str'> \tTrimming: \n",
      "\t\"true\"\n",
      "\n",
      "<class 'str'> \tMarkDuplicates: \n",
      "\t\"true\"\n",
      "\n",
      "<class 'str'> \tBqsr: \n",
      "\t\"true\"\n",
      "\n",
      "<class 'str'> \tVqsr: \n",
      "\t\"true\"\n",
      "\n",
      "<class 'str'> \tInputReads: \n",
      "\t\"/projects/bioinformatics/DEL/Inputs/WGS_chr1_5X_E0.005_L1_read1.fastq.gz,/projects/bioinformatics/DEL/Inputs/WGS_chr1_5X_E0.005_L1_read2.fastq.gz\"\n",
      "\n",
      "<class 'str'> \tNormalInputRead1: \n",
      "\t\"/projects/bioinformatics/DEL/Inputs/WGS_chr1_5X_E0.005_L1_read1.fastq.gz,/projects/bioinformatics/DEL/Inputs/WGS_chr1_5X_E0.005_L2_read1.fastq.gz\"\n",
      "\n",
      "<class 'str'> \tNormalInputRead2: \n",
      "\t\"/projects/bioinformatics/DEL/Inputs/WGS_chr1_5X_E0.005_L1_read2.fastq.gz,/projects/bioinformatics/DEL/Inputs/WGS_chr1_5X_E0.005_L2_read2.fastq.gz\"\n",
      "\n",
      "<class 'str'> \tAdapters: \n",
      "\t\"/projects/bioinformatics/DEL/Inputs/TruSeqAdaptors.fasta\"\n",
      "\n",
      "<class 'str'> \tRef: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Homo_sapiens_assembly38.fasta\"\n",
      "\n",
      "<class 'str'> \tRefAnn: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Homo_sapiens_assembly38.fasta.ann\"\n",
      "\n",
      "<class 'str'> \tRefSa: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Homo_sapiens_assembly38.fasta.sa\"\n",
      "\n",
      "<class 'str'> \tRefBwt: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Homo_sapiens_assembly38.fasta.bwt\"\n",
      "\n",
      "<class 'str'> \tRefPac: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Homo_sapiens_assembly38.fasta.pac\"\n",
      "\n",
      "<class 'str'> \tRefAmb: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Homo_sapiens_assembly38.fasta.amb\"\n",
      "\n",
      "<class 'str'> \tRefFai: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Homo_sapiens_assembly38.fasta.fai\"\n",
      "\n",
      "<class 'str'> \tPlatform: \n",
      "\t\"ILLUMINA\"\n",
      "\n",
      "<class 'str'> \tLibrary: \n",
      "\t\"fake_lib\"\n",
      "\n",
      "<class 'str'> \tCenterName: \n",
      "\t\"some_seq_center\"\n",
      "\n",
      "<class 'str'> \tPlatformUnit: \n",
      "\t\"FLOWCELL_BARCODE.LANE.SAMPLE_BARCODE,FLOWCELL_BARCODE.LANE.SAMPLE_BARCODE\"\n",
      "\n",
      "<class 'str'> \tChunkSizeInBases: \n",
      "\t\"10000000\"\n",
      "\n",
      "<class 'str'> \tBqsrKnownSites: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Mills_and_1000G_gold_standard.indels.hg38.vcf,/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/dbsnp_138.hg38.vcf\"\n",
      "\n",
      "<class 'str'> \tRealignmentKnownSites: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Mills_and_1000G_gold_standard.indels.hg38.vcf\"\n",
      "\n",
      "<class 'str'> \tDBSNP: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/dbsnp_138.hg38.vcf\"\n",
      "\n",
      "<class 'str'> \tDBSNPIdx: \n",
      "\t\"/projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/dbsnp_138.hg38.vcf.idx\"\n",
      "\n",
      "<class 'str'> \tVqsrSnpResourceString: \n",
      "\t'--resource /projects/bioinformatics/DataPacks/human/gatk_bundle_Oct_2017/gatk_bundle_hg38/1000G_phase1.snps.high_confidence.hg38.vcf.gz --resource_param 1000G,known false,training true,truth false,prior 10.0 --resource /projects/bioinformatics/DataPacks/human/gatk_bundle_Oct_2017/gatk_bundle_hg38/1000G_omni2.5.hg38.vcf.gz --resource_param omni,known false,training true,truth false,prior 12.0 --resource /projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/dbsnp_138.hg38.vcf --resource_param dbsnp,known true,training false,truth false,prior 2.0 --resource /projects/bioinformatics/DataPacks/human/gatk_bundle_Oct_2017/gatk_bundle_hg38/hapmap_3.3.hg38.vcf.gz --resource_param hapmap,known false,training true,truth true,prior 15.0'\n",
      "\n",
      "<class 'str'> \tVqsrIndelResourceString: \n",
      "\t'--resource /projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/dbsnp_138.hg38.vcf --resource_param dbsnp,known true,training false,truth false,prior 2.0 --resource /projects/mgc/Project_1/MayomicsVC_MayoTesting/Reference/Mills_and_1000G_gold_standard.indels.hg38.vcf --resource_param Mills,known false,training true,truth true,prior 12.0'\n",
      "\n",
      "<class 'str'> \tHaplotyperExtraOptionsString: \n",
      "\t'--emit_mode variant --gq_bands 1-60,60-99/19,99 --min_base_qual 10 --pcr_indel_model CONSERVATIVE --phasing 1 --ploidy 2 --prune_factor 2'\n",
      "\n",
      "<class 'str'> \tBWAExtraOptionsString: \n",
      "\t'-M'\n",
      "\n",
      "<class 'str'> \tAnnotateText: \n",
      "\t'--annotation DP --annotation QD --annotation FS --annotation SOR --annotation MQ --annotation MQRankSum --annotation ReadPosRankSum'\n",
      "\n",
      "<class 'str'> \tDeliveryFolder_Alignment: \n",
      "\t\"/projects/bioinformatics/DEL/Delivery/Alignment\"\n",
      "\n",
      "<class 'str'> \tDeliveryFolder_HaplotyperVC: \n",
      "\t\"/projects/bioinformatics/DEL/Delivery/HaplotyperVC\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_dict = get_keys_dict(config_full_file=config_full_files[0])\n",
    "print('\\n\\n')\n",
    "for k, v in config_dict.items():\n",
    "    print(type(v), '\\t%s: \\n\\t%s\\n'%(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def template_del_keys(config_file, key_names_list):\n",
    "    \"\"\" Usage: new_lines_list = template_del_keys(config_file, key_names_list) \"\"\"\n",
    "    \n",
    "    print('Opening:\\n', config_file)\n",
    "    with open(config_file, 'r') as tfh:\n",
    "        lines = tfh.readlines()\n",
    "    print('found %i lines'%(len(lines)))\n",
    "    new_lines_list = ['{\\n']\n",
    "    for line in lines:\n",
    "        l_key = line.strip().split('=')[0]\n",
    "        for key_name in key_names_list:\n",
    "            if not key_name in l_key:\n",
    "                new_lines_list.append('  ' + line.strip() + '\\n')\n",
    "            else:\n",
    "                print('removeing\\n', line.strip())\n",
    "                \n",
    "    new_lines_list.append('}')\n",
    "    outie_full_file, fext = os.path.splitext(config_file)\n",
    "    outie_full_file = outie_full_file + '.cleaned' + fext\n",
    "    print(outie_full_file)\n",
    "    \n",
    "    return new_lines_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 170 lines\n",
      "<class 'list'>\n",
      "{\n",
      "RealignSoftMemLimit\n",
      "DebugMode\n",
      "Bqsr\n",
      "VqsrHardMemLimit\n",
      "BashSharedFunctions\n",
      "BashPreamble\n",
      "MergeBamEnvProfile\n",
      "BashPreamble\n",
      "BqsrSoftMemLimit\n",
      "BashPreamble\n",
      "BashSharedFunctions\n",
      "Sentieon\n",
      "CenterName\n",
      "VqsrSoftMemLimit\n",
      "BqsrHardMemLimit\n",
      "AlignEnvProfile\n",
      "AnnotateText\n",
      "RefPac\n",
      "TrimSoftMemLimit\n",
      "BashSharedFunctions\n",
      "Ref\n",
      "HaplotyperSoftMemLimit\n",
      "BqsrKnownSites\n",
      "RealignHardMemLimit\n",
      "DebugMode\n",
      "SentieonThreads\n",
      "SentieonThreads\n",
      "RefFai\n",
      "HaplotyperEnvProfile\n",
      "SentieonThreads\n",
      "MarkDuplicates\n",
      "BashPreamble\n",
      "RefBwt\n",
      "Platform\n",
      "RealignmentScript\n",
      "NormalInputReads\n",
      "TrimHardMemLimit\n",
      "RefFai\n",
      "BashPreamble\n",
      "BashSharedFunctions\n",
      "DebugMode\n",
      "WorkflowJson\n",
      "PairedEnd\n",
      "BashPreamble\n",
      "TrimEnvProfile\n",
      "MergeBamScript\n",
      "RefSa\n",
      "SampleName\n",
      "DedupScript\n",
      "Ref\n",
      "AlignSoftMemLimit\n",
      "RefFai\n",
      "DebugMode\n",
      "Sentieon\n",
      "BashSharedFunctions\n",
      "Sentieon\n",
      "AlignmentScript\n",
      "RefPac\n",
      "BashSharedFunctions\n",
      "DeliveryHaplotyperVC_Script\n",
      "HaplotyperVCFSourceField\n",
      "DebugMode\n",
      "AlignSoftMemLimit\n",
      "DBSNP\n",
      "VqsrIndelResourceString\n",
      "DeliveryFolder_HaplotyperVC\n",
      "DeliveryFolder_Alignment\n",
      "VqsrScript\n",
      "PlatformUnit\n",
      "RefBwt\n",
      "DebugMode\n",
      "PairedEnd\n",
      "HaplotyperScript\n",
      "Vqsr\n",
      "VqsrSnpResourceString\n",
      "SampleName\n",
      "DedupEnvProfile\n",
      "RefAmb\n",
      "BashPreamble\n",
      "SampleName\n",
      "CenterName\n",
      "SampleName\n",
      "Sentieon\n",
      "Sentieon\n",
      "SentieonThreads\n",
      "Platform\n",
      "RealignmentKnownSites\n",
      "BqsrScript\n",
      "AlignHardMemLimit\n",
      "DebugMode\n",
      "SampleName\n",
      "HaplotyperExtraOptionsString\n",
      "VqsrEnvProfile\n",
      "AlignEnvProfile\n",
      "TrimSeqScript\n",
      "CutAdaptThreads\n",
      "BqsrEnvProfile\n",
      "BashPreamble\n",
      "DebugMode\n",
      "BashPreamble\n",
      "SentieonThreads\n",
      "DebugMode\n",
      "Library\n",
      "Ref\n",
      "BashSharedFunctions\n",
      "PairedEnd\n",
      "TrimSeqScript\n",
      "AlignHardMemLimit\n",
      "SampleName\n",
      "DeliveryAlignment_Script\n",
      "HaplotyperHardMemLimit\n",
      "Ref\n",
      "SampleName\n",
      "Adapters\n",
      "Ref\n",
      "RefSa\n",
      "TrimHardMemLimit\n",
      "ChunkSizeInBases\n",
      "RefAnn\n",
      "CutAdaptThreads\n",
      "SentieonThreads\n",
      "DedupHardMemLimit\n",
      "SampleName\n",
      "RefFai\n",
      "RefAnn\n",
      "SampleName\n",
      "BashSharedFunctions\n",
      "PairedEnd\n",
      "SampleName\n",
      "Library\n",
      "BashPreamble\n",
      "DebugMode\n",
      "CutAdapt\n",
      "Sentieon\n",
      "SampleName\n",
      "SampleName\n",
      "DebugMode\n",
      "WorkflowJson\n",
      "PairedEnd\n",
      "PairedEnd\n",
      "ChunkSizeInBases\n",
      "Trimming\n",
      "BashPreamble\n",
      "CutAdapt\n",
      "DBSNPIdx\n",
      "TrimSoftMemLimit\n",
      "BashSharedFunctions\n",
      "BashSharedFunctions\n",
      "BashPreamble\n",
      "BashSharedFunctions\n",
      "DebugMode\n",
      "TrimEnvProfile\n",
      "RealignEnvProfile\n",
      "RefAmb\n",
      "SentieonThreads\n",
      "BWAExtraOptionsString\n",
      "SentieonThreads\n",
      "AlignmentScript\n",
      "MergeHardMemLimit\n",
      "BWAExtraOptionsString\n",
      "Sentieon\n",
      "Sentieon\n",
      "MergeSoftMemLimit\n",
      "Ref\n",
      "Adapters\n",
      "DedupSoftMemLimit\n",
      "BashSharedFunctions\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_test_template = os.path.join(json_dir, 'GermlineMasterWorkflow.templateSAVEME.json')\n",
    "keys_list = get_json_keys_list(json_test_template)\n",
    "print(type(keys_list))\n",
    "for key in keys_list:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
