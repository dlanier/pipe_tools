{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "sys.path.insert(1, '../../../MayomicsVC/testing')\n",
    "from integration_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          File: 123\n",
      "                        String: 114\n",
      "                         File?: 1\n",
      "                       Boolean: 2\n",
      "                   Array[File]: 2\n"
     ]
    }
   ],
   "source": [
    "wdl_base_dir = '../../../MayomicsVC/src/wdl'\n",
    "types_dict = get_task_types(wdl_directory=wdl_base_dir)\n",
    "for k, v in types_dict.items():\n",
    "    print('%30s: %s'%(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wdl_file_variables_dict(full_filename):\n",
    "    \"\"\" Usage  config_orderd_dict = get_wdl_file_variables_dict(full_filename, task_types_list)\n",
    "    Get the sorted list of variables and their types from the wdl files in a directory tree\n",
    "    \n",
    "    Args:\n",
    "        wdl_directory:       (default to run directory if not valid directory name)\n",
    "        \n",
    "    Returns:\n",
    "        config_ordered_dict: python OrderedDict of  variable_name: \"type_name\" \n",
    "    \"\"\"\n",
    "    skip_line_chars = ['#', '<', '>']\n",
    "    base_path, fname = os.path.split(full_filename)\n",
    "    types_dict = get_task_types(wdl_directory=base_path)\n",
    "    for k, v in types_dict.items():\n",
    "        print('%30s: %s'%(k,v))\n",
    "    task_types_list = list(types_dict.keys())\n",
    "    config_vars_dict = {}\n",
    "    with open(full_filename, 'r') as fh:\n",
    "        lines = fh.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        l = line.strip()\n",
    "        if len(l) > 0 and not l[0] in skip_line_chars:\n",
    "            line_words_list = l.split()\n",
    "            first_word = line_words_list[0]\n",
    "            if first_word in task_types_list:\n",
    "                second_word = line_words_list[1]\n",
    "                if not second_word in config_vars_dict.keys():\n",
    "                    config_vars_dict[second_word] = '\"' + first_word + '\"'\n",
    "\n",
    "                elif first_word != config_vars_dict[second_word][1:-1]:\n",
    "                    bugger = config_vars_dict[second_word][:-1]\n",
    "                    config_vars_dict[second_word] = bugger + ', ' + first_word  + '\"'\n",
    "                                \n",
    "    config_od = OrderedDict()\n",
    "    for k, v in sorted(config_vars_dict.items()):\n",
    "        config_od[k] = v\n",
    "\n",
    "    return config_od\n",
    "\n",
    "def get_file_segment(full_filename, section_word):\n",
    "    \"\"\" Usage: segment_text_list = get_file_segment(full_filename, section_word) \"\"\"\n",
    "    opener_char = '{'\n",
    "    opener_count = 0\n",
    "    closer_char = '}'\n",
    "    closer_count = 0\n",
    "    segment_text_list = []\n",
    "    with open(full_filename, 'r') as fh:\n",
    "        lines = fh.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        if len(line) > 0:\n",
    "            l = line.strip()\n",
    "            if opener_count > closer_count:\n",
    "                segment_text_list.append(l)\n",
    "                opener_count += l.count(opener_char)\n",
    "                closer_count += l.count(closer_char)\n",
    "                \n",
    "            if section_word in l:\n",
    "                segment_text_list.append(l)\n",
    "                opener_count += l.count(opener_char)\n",
    "                closer_count += l.count(closer_char)\n",
    "                \n",
    "    return segment_text_list\n",
    "\n",
    "def get_typed_vars(text_list):\n",
    "    \"\"\" Usage: vars_dict = get_typed_vars(text_list) \"\"\"\n",
    "    vars_dict = {}\n",
    "    skippies = ['{']\n",
    "    for line in text_list:\n",
    "        l = line.strip().split()\n",
    "        if len(l) ==  2:\n",
    "            skipit = False\n",
    "            for w in l:\n",
    "                if skippies[0] in w:\n",
    "                    skipit = True\n",
    "            if skipit == False:\n",
    "                vars_dict[l[1]] = l[0]\n",
    "                \n",
    "    typed_vars_od = OrderedDict()\n",
    "    for k, v in sorted(vars_dict.items()):\n",
    "        typed_vars_od[k] = v\n",
    "        \n",
    "    return typed_vars_od\n",
    "\n",
    "def get_file_segment_variables(full_filename, section_word):\n",
    "    \"\"\" Usage: vars_type_orderdict = get_file_segment_variables(full_filename, section_word) \"\"\"\n",
    "    return get_typed_vars(get_file_segment(full_file, section_word))\n",
    "    \n",
    "def get_import_files_dict(full_filename):\n",
    "    \"\"\" Usage: files_dict = get_import_files_dict(full_filename) \"\"\"\n",
    "    import_string = 'import'\n",
    "    files_dict = {}\n",
    "    with open(full_filename, 'r') as fh:\n",
    "        lines = fh.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        line_list = line.strip().split()\n",
    "        if len(line_list) > 1 and line_list[0] == import_string:\n",
    "            files_dict[line_list[-1]] = line_list[1].strip('\"')\n",
    "            \n",
    "    return files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  CUTADAPTTRIM: MayomicsVC/src/wdl/Alignment/TestTasks/Runtrim_sequences.wdl\n",
      "                     ALIGNMENT: MayomicsVC/src/wdl/Alignment/TestTasks/Runalignment.wdl\n",
      "                      MERGEBAM: MayomicsVC/src/wdl/Alignment/Tasks/merge_aligned_bam.wdl\n",
      "                         DEDUP: MayomicsVC/src/wdl/Alignment/Tasks/dedup.wdl\n",
      "             DELIVER_Alignment: MayomicsVC/src/wdl/DeliveryOfAlignment/Tasks/deliver_alignment.wdl\n",
      "                   REALIGNMENT: MayomicsVC/src/wdl/HaplotyperVC/Tasks/realignment.wdl\n",
      "                          BQSR: MayomicsVC/src/wdl/HaplotyperVC/Tasks/bqsr.wdl\n",
      "                    HAPLOTYPER: MayomicsVC/src/wdl/HaplotyperVC/Tasks/haplotyper.wdl\n",
      "                          VQSR: MayomicsVC/src/wdl/HaplotyperVC/Tasks/vqsr.wdl\n",
      "          DELIVER_HaplotyperVC: MayomicsVC/src/wdl/DeliveryOfHaplotyperVC/Tasks/deliver_HaplotyperVC.wdl\n"
     ]
    }
   ],
   "source": [
    "wdl_base_dir = '../../../MayomicsVC/src/wdl'\n",
    "# types_dict = ingrat.get_task_types(wdl_directory=wdl_base_dir)\n",
    "wdl_file_inq = 'GermlineMasterWorkflow.wdl'\n",
    "full_file = os.path.join(wdl_base_dir, wdl_file_inq)\n",
    "\n",
    "files_dict = get_import_files_dict(full_filename = full_file)\n",
    "for k, f in files_dict.items():\n",
    "    print('%30s: %s'%(k,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Bqsr: Boolean\n",
      "                MarkDuplicates: Boolean\n",
      "              NormalInputReads: Array[Array[File]]\n",
      "                      Trimming: Boolean\n",
      "                          Vqsr: Boolean\n"
     ]
    }
   ],
   "source": [
    "section_word = 'workflow'\n",
    "wdl_base_dir = '../../../MayomicsVC/src/wdl'\n",
    "# types_dict = ingrat.get_task_types(wdl_directory=wdl_base_dir)\n",
    "wdl_file_inq = 'GermlineMasterWorkflow.wdl'\n",
    "full_file = os.path.join(wdl_base_dir, wdl_file_inq)\n",
    "\n",
    "vars_type_orderdict = get_file_segment_variables(full_file, section_word)\n",
    "for v, vt in vars_type_orderdict.items():\n",
    "    print('%30s: %s'%(v,vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          File: 123\n",
      "                        String: 114\n",
      "                         File?: 1\n",
      "                       Boolean: 2\n",
      "                   Array[File]: 2\n",
      "                          Bqsr: \"Boolean\"\n",
      "        DeliverAlignOutputBais: \"File\"\n",
      "        DeliverAlignOutputBams: \"File\"\n",
      "          DeliverHaplotyperVcf: \"File\"\n",
      "       DeliverHaplotyperVcfIdx: \"File\"\n",
      "                MarkDuplicates: \"Boolean\"\n",
      "                      Trimming: \"Boolean\"\n",
      "                          Vqsr: \"Boolean\"\n"
     ]
    }
   ],
   "source": [
    "wdl_base_dir = '../../../MayomicsVC/src/wdl'\n",
    "# types_dict = ingrat.get_task_types(wdl_directory=wdl_base_dir)\n",
    "wdl_file_inq = 'GermlineMasterWorkflow.wdl'\n",
    "full_file = os.path.join(wdl_base_dir, wdl_file_inq)\n",
    "# os.listdir(wdl_base_dir)\n",
    "task_types_list = list(types_dict.keys())\n",
    "\n",
    "if os.path.isfile(full_file):\n",
    "    config_orderd_dict = get_wdl_file_variables_dict(full_file)\n",
    "    for k, v in config_orderd_dict.items():\n",
    "        print('%30s: %s'%(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
